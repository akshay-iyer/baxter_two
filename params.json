{"name":"Baxter two","tagline":"","body":"Group 2 - Final Project\r\n=========================\r\n\r\n\r\n\r\n##About##\r\n\r\nA ROS project developed for Northwestern ME495 - Embedded Systems in Robotics. This *baxter_two* package is used to control Baxter, a robot created by [Rethink Robotics], allowing Baxter to recognize several objects placed on a table, pick up the objects, and move them to a specified goal location. \r\n\r\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/RkelMrtiU3E\" frameborder=\"0\" allowfullscreen></iframe>\r\n\r\nTo launch (in a ROS workspace):\r\n\r\n```bash\r\ncd ~/baxter_ws/\r\n. baxter.sh\r\nrosrun baxter_tools enable_robot.py -e\r\nroslaunch baxter_two baxter_two.launch\r\n```\r\nTo run this demo on the Baxter simulation, use `roslaunch baxter_gazebo baxter_world.launch` to start up the simulator, and replace `. baxter.sh` with `. baxter.sh sim`.\r\n\r\n**NOTE:** Prerequisites to set up workspace are listed as follows:\r\n\r\n1.\tInstall the [Baxter SDK]\r\n2.\tInstall [MoveIt!]\r\n3.\tDownload [moveit_python] by Michael Ferguson\r\n4.\tInstall Baxter Simulator (if running the simulation) **\r\n\r\n**This must use version 1.1 of the simulator\r\n\r\n##Package Contents##\r\n\r\nLaunch file:\r\n-`baxter_two.launch`\r\n\t-Launches joint trajectory server, MoveIt! with rviz, baxter_img, and baxter_pnp.\r\n\r\nnodes:\r\n-baxter_img\r\n\t-Subscribes to the `/cameras/right_hand_camera/image` topic, calculates cube locations using OpenCV tools, and publishes this information\r\n-baxter_pnp\r\n\t-Subscribes to the topic published to by *baxter_img*, then utilizes `PlanningSceneInterface` and `MoveGroupInterface` from *moveit_python* ** to create Baxter's world including the detected objects and plan/execute paths. \r\n\t-Uses `baxter_interface` for gripper control\r\n\r\n\r\n**Using these bindings, other capabilities include:\r\n\t\t-executing planned paths in both joint space and cartesian space\r\n\t\t-populating planning environment with collision objects\r\n\t\t-allows velocity scaling\r\n\r\n\r\n\r\n##Overview##\r\n\r\nThis package utilizes tools offered in several different existing packages. The primary package used in Baxter's pick and place movements is the [MoveIt!] motion planning framework, paired with the [moveit_python] Python bindings created by Michael Ferguson. Additionally, [OpenCV] was used to locate the objects using one of Baxter's built-in cameras. This pick-and-place technique utilizes the built-in camera on Baxter's right arm to search for green cubes in the task space. Large green cubes are stacked on top of one another in the goal space, while small green cubes are simply placed in the goal space. Positions of objects can be dynamically repositioned and reoriented, and Baxter will continue to pick and place these object until there are no more object in the task space. \r\n\r\n##Important Nodes and Topics##\r\n\r\nThere are two nodes that are run in this package. The first node, `baxter_img`, subscribes to the `/cameras/right_hand_camera/image` topic, calculates cube locations using OpenCV tools, and publishes a `PoseArray()` message via the `DPos` topic to the second node, `baxter_pnp`. `baxter_pnp` then subscribes to the `DPos` published to by `baxter_img`. Then, it utilizes `PlanningSceneInterface` and `MoveGroupInterface` from *moveit_python* to create Baxter's world including the detected objects and plan/execute paths. \r\n\r\n\r\n##Future Work##\r\n\r\n* One potential area of improvement for this package is in the camera calibration. currently, variations in surrounding lighting affect the object detection success. Using more finely-tuned methods of calibrating the camera will minimize the lighting issue. \r\n\r\n* Another area is in creating a Graphical User Interface that allows the user to click an object in the virtual world created by Baxter, and pick and place that particular item. In the current state, Baxter will pick up the object that it detects to be closest to itself. Currently, a GUI is under development that utilizes Gazebo pugin functionality. This GUI, when complete, would allow the user to choose an object presented in the Gazebo world, and click a button to execute the pick-and-place action.\r\n\r\n\r\n\r\n\r\n\r\n[Rethink Robotics]: http://www.rethinkrobotics.com/baxter/\r\n[MoveIt!]: https://github.com/RethinkRobotics/sdk-docs/wiki/MoveIt-Tutorial#tutorial\r\n[Baxter setup instructions]: http://sdk.rethinkrobotics.com/wiki/Getting_Started\r\n[here]: http://sdk.rethinkrobotics.com/wiki/Simulator_Installation\r\n[moveit_python]: https://github.com/mikeferguson/moveit_python\r\n[this tutorial]: https://github.com/RethinkRobotics/sdk-docs/wiki/MoveIt-Tutorial#tutorial\r\n[OpenCV]: http://opencv.org/\r\n[these instructions]: http://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}
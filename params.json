{"name":"Baxter two","tagline":"","body":"Baxter Pick 'n' Place Project\r\n=========================\r\n\r\n## About ##\r\n\r\nA ROS project as part of ME495 - Embedded Systems in Robotics course at Northwestern University (NU). \r\n\r\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/RkelMrtiU3E\" frameborder=\"0\" allowfullscreen></iframe>\r\n\r\nTo launch (in a ROS workspace), type in terminal:\r\n```\r\ncd ~/baxter_ws/\r\n. baxter.sh\r\nrosrun baxter_tools enable_robot.py -e\r\nroslaunch baxter_two baxter_two.launch\r\n```\r\n\r\n## Goal of Project ##\r\n\r\n**Use baxter to pick and place objects from one location to another**\r\n\r\n## Tutorial ##\r\n\r\nThe following sections describe contents of this package:\r\n\r\n### 1. Prerequisites ###\r\n\r\nThe following packages need to be installed for `baxter_two` package to work: \r\n\r\n1. [Baxter SDK] - to be installed in baxter_ws/src directory\r\n2. [MoveIt!]\r\n3. [moveit_python] by Michael Ferguson - to be installed in baxter_ws/src directory\r\n4. Baxter Simulator - v1.1 (ONLY needed if NOT working with actual baxter robot)\r\n\r\n### 2. Package Contents ###\r\n\r\nThe `baxter_two` package consists of following main files:\r\n\r\n* **baxter_two.launch**: A launch file that starts the following nodes:\r\n\t* joint_action_trajectory_server.py (required for MoveIt!)\r\n\t* MoveIt! with rviz\r\n\t* baxter_img.cpp\r\n\t* baxter_pnp.py\r\n\r\n* **baxter_img.cpp**: subscribes to the `/cameras/right_hand_camera/image` topic, calculates object locations using OpenCV tools, and publishes this information to `baxter_pnp` node via a `PoseArray()` message\r\n\r\n* **baxter_pnp.py**: subscribes to the topic (called `Dpos`) published by *baxter_img*, and calls `PlanningSceneInterface` and `MoveGroupInterface` classes from `moveit_python` bindings to add collision objects and move baxter's arms respectively\r\n\t* Allows both arms to be moved at the same time\r\n\t* Allows velocity scaling using `max_velocity_scaling_factor`\r\n\t* Uses `baxter_interface` for gripper control\r\n\r\n### 3. Step-by-step guide ###\r\n\r\nThis section gives a step-by-step approach to run a successful baxter pick and place with this package. \r\n\r\na. Items needed - a table of height ~ 0.6 m; square blocks (with green top surface); a baxter robot with electric parallel grippers; an ethernet cable (to connect baxter to computer); \r\nb. Set up networking with baxter\r\nc. \r\n\r\n\r\n\r\n##Overview##\r\n\r\nThis package utilizes tools offered in several different existing packages. The primary package used in Baxter's pick and place movements is the [MoveIt!] motion planning framework, paired with the [moveit_python] Python bindings created by Michael Ferguson. Additionally, [OpenCV] was used to locate the objects using one of Baxter's built-in cameras. This pick-and-place technique utilizes the built-in camera on Baxter's right arm to search for green cubes in the task space. Large green cubes are stacked on top of one another in the goal space, while small green cubes are simply placed in the goal space. Positions of objects can be dynamically repositioned and reoriented, and Baxter will continue to pick and place these object until there are no more object in the task space. \r\n\r\n##Important Nodes and Topics##\r\n\r\nThere are two nodes that are run in this package. The first node, `baxter_img`, subscribes to the `/cameras/right_hand_camera/image` topic, calculates cube locations using OpenCV tools, and publishes a `PoseArray()` message via the `DPos` topic to the second node, `baxter_pnp`. `baxter_pnp` then subscribes to the `DPos` published to by `baxter_img`. Then, it utilizes `PlanningSceneInterface` and `MoveGroupInterface` from *moveit_python* to create Baxter's world including the detected objects and plan/execute paths. \r\n\r\n\r\n##Future Work##\r\n\r\n* One potential area of improvement for this package is in the camera calibration. currently, variations in surrounding lighting affect the object detection success. Using more finely-tuned methods of calibrating the camera will minimize the lighting issue. \r\n\r\n* Another area is in creating a Graphical User Interface that allows the user to click an object in the virtual world created by Baxter, and pick and place that particular item. In the current state, Baxter will pick up the object that it detects to be closest to itself. Currently, a GUI is under development that utilizes Gazebo pugin functionality. This GUI, when complete, would allow the user to choose an object presented in the Gazebo world, and click a button to execute the pick-and-place action.\r\n\r\n\r\n\r\n\r\n\r\n[Rethink Robotics]: http://www.rethinkrobotics.com/baxter/\r\n[MoveIt!]: https://github.com/RethinkRobotics/sdk-docs/wiki/MoveIt-Tutorial#tutorial\r\n[Baxter setup instructions]: http://sdk.rethinkrobotics.com/wiki/Getting_Started\r\n[here]: http://sdk.rethinkrobotics.com/wiki/Simulator_Installation\r\n[moveit_python]: https://github.com/mikeferguson/moveit_python\r\n[this tutorial]: https://github.com/RethinkRobotics/sdk-docs/wiki/MoveIt-Tutorial#tutorial\r\n[OpenCV]: http://opencv.org/\r\n[these instructions]: http://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}